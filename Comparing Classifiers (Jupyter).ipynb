{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Comparison (using scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this segment, we'll compare the accuracy of 6 ML algorithms. This'll also serve as an intro to using scikit-learn\n",
    "\n",
    "#### Importing various toolkits I'll be needing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I'll be importing the classifiers from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using genfromtext to import the dataset in a numpy array format to be compatible with sklearn's methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_dataset = genfromtxt(\"data.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load features (column data) and target (response) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transport_dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response variable needs to be a single column which has the numeric representation of classes. I have extracted the class labels from the original data and put them in a new CSV file named 'data_target.csv'. I'll be importing that in this block using the genfromtxt to convert it to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = genfromtxt(\"data_target.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data types to make sure we've got the variables in the necessary format for the sklearn toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perfect. Let's move on and check the dimensions of the data to ensure it's been imported correctly into our feature and response variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset dimensions\n",
      "(21000, 129)\n",
      "(21000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset dimensions\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE - I'm going to first be checking the training accuracies in this section to see how the algorithms perform on the training data. I'll be comparing these results to the accuracy of the split data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We instantiate the models as follows (mostly using default parameters, except for random forest in which we use 100 estimators instead of 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the models (using the default parameters)\n",
    "naive = GaussianNB()\n",
    "logreg = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "svm = SVC(gamma='scale')\n",
    "randomforest = RandomForestClassifier(n_estimators=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we've created the instances, I'm going to train the data using the fit() function of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "f:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the models with data\n",
    "naive.fit(X,y)\n",
    "logreg.fit(X, y)\n",
    "knn.fit(X, y)\n",
    "decision_tree.fit(X,y)\n",
    "svm.fit(X,y)\n",
    "randomforest.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict response values using .predict() function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 6., 6., 6.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive.predict(X)\n",
    "logreg.predict(X)\n",
    "knn.predict(X)\n",
    "decision_tree.predict(X)\n",
    "svm.predict(X)\n",
    "randomforest.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the values in variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_predicted = naive.predict(X)\n",
    "logreg_predicted = logreg.predict(X)\n",
    "knn_predicted = knn.predict(X)\n",
    "decision_tree_predicted = decision_tree.predict(X)\n",
    "svm_predicted = svm.predict(X)\n",
    "randomforest_predicted = randomforest.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To ensure all values predicted have the right number of dimensions, we check the size of the resulting arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n"
     ]
    }
   ],
   "source": [
    "print(len(naive_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n"
     ]
    }
   ],
   "source": [
    "print(len(logreg_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n"
     ]
    }
   ],
   "source": [
    "print(len(knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n"
     ]
    }
   ],
   "source": [
    "print(len(decision_tree_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n"
     ]
    }
   ],
   "source": [
    "print(len(svm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n"
     ]
    }
   ],
   "source": [
    "print(len(randomforest_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have thus verified that the resulting data does indeed have the correct dimensions and works as we expect it to \n",
    "\n",
    "### Now we check how accurately the classifiers predict their training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy score\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes accuracy score\")\n",
    "print(metrics.accuracy_score(y, naive_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score\n",
      "0.9245714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression accuracy score\")\n",
    "print(metrics.accuracy_score(y, logreg_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy score\n",
      "0.9747619047619047\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN accuracy score\")\n",
    "print(metrics.accuracy_score(y,knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree accuracy score\")\n",
    "print(metrics.accuracy_score(y,decision_tree_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy score\n",
      "0.9944761904761905\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM accuracy score\")\n",
    "print(metrics.accuracy_score(y,svm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy score\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Random forest accuracy score\")\n",
    "print(metrics.accuracy_score(y,randomforest_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above result is the highest possible values these classifiers will have for the data. Now we split the data into 80% training and 20% test and repeat the procedure on the resulting datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the split accuracies\n"
     ]
    }
   ],
   "source": [
    "#Calculating the split accuracy\n",
    "print(\"Calculating the split accuracies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "f:\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting models\n",
    "naive.fit(X_train,y_train)\n",
    "logreg.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train,y_train)\n",
    "svm.fit(X_train,y_train)\n",
    "randomforest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note here that we've switched to predicting values based on the test dataset (20% of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 5., 2., ..., 3., 3., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting response values as before\n",
    "naive.predict(X_test)\n",
    "logreg.predict(X_test)\n",
    "knn.predict(X_test)\n",
    "decision_tree.predict(X_test)\n",
    "svm.predict(X_test)\n",
    "randomforest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the predicted response values\n",
    "naive_split_predicted = naive.predict(X_test)\n",
    "logreg_split_predicted = logreg.predict(X_test)\n",
    "knn_split_predicted = knn.predict(X_test)\n",
    "decision_tree_split_predicted = decision_tree.predict(X_test)\n",
    "svm_split_predicted = svm.predict(X_test)\n",
    "randomforest_split_predicted = randomforest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200\n",
      "4200\n",
      "4200\n",
      "4200\n",
      "4200\n",
      "4200\n"
     ]
    }
   ],
   "source": [
    "# checking for integrity of classifiers\n",
    "print(len(naive_split_predicted))\n",
    "print(len(logreg_split_predicted))\n",
    "print(len(knn_split_predicted))\n",
    "print(len(decision_tree_split_predicted))\n",
    "print(len(svm_split_predicted))\n",
    "print(len(randomforest_split_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, calculate the accuracy metrics, with respect to the original target values (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy score\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes accuracy score\")\n",
    "print(metrics.accuracy_score(y_test, naive_split_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score\n",
      "0.9230952380952381\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression accuracy score\")\n",
    "print(metrics.accuracy_score(y_test, logreg_split_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy score\n",
      "0.9633333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN accuracy score\")\n",
    "print(metrics.accuracy_score(y_test,knn_split_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree accuracy score\")\n",
    "print(metrics.accuracy_score(y_test,decision_tree_split_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine accuracy score\n",
      "0.9911904761904762\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machine accuracy score\")\n",
    "print(metrics.accuracy_score(y_test,svm_split_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy score\n",
      "0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest accuracy score\")\n",
    "print(metrics.accuracy_score(y_test,randomforest_split_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice that the predicted values on the split data are somewhat close to the predicted values on the training data, but just fall short of being quite as accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see, the decision tree and naive bayes classifiers perform the best (100% accuracy) on this particular dataset. However, this is only based on the default parameters, and classifiers like K-Nearest Neighbors might do better than this if we increase the value of K, for instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's worth noting that the classifier that works best on a particular dataset does not imply that it's generally a better classifier than the others. It only means the data distribution is conducive to its classification ability. \n",
    "\n",
    "### Being a data scientist is about understanding the math/mechanics behind the classifier and to an extent knowing WHY the particular classifier performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Cheers,\n",
    "   ## Rahul"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
